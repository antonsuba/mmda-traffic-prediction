{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set(style='ticks', color_codes=True)\n",
    "\n",
    "# from pandas.plotting import parallel_coordinates\n",
    "from sklearn import preprocessing\n",
    "from operator import itemgetter\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# pd.set_option('display.max_columns', 150)\n",
    "pd.options.display.max_seq_items = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = 'data/train.csv'\n",
    "TEST_DATA = 'data/test.csv'\n",
    "CLEAN_TRAIN_DATA = 'data/clean_train_data.csv'\n",
    "\n",
    "NOISE_COLUMNS = ['Key', 'No', 'District', 'City', 'Hour', 'Minute', 'Date', 'Month', 'Year',\n",
    "                'JunctionControl', 'dayInWeek', 'IsDayOrNight', 'CollisionDirection', 'DetailCause',\n",
    "                'Tricycle', 'Weather', 'AccidentCause']\n",
    "NOISE_TEST_COLUMNS = ['Key', 'District', 'City', 'Hour', 'Minute', 'Date', 'Month', 'Year',\n",
    "                'JunctionControl', 'dayInWeek', 'IsDayOrNight', 'CollisionDirection', 'DetailCause',\n",
    "                'Tricycle', 'Weather', 'AccidentCause']\n",
    "\n",
    "NORMALIZE_COLUMNS = ['DriversKilled', 'DriversInjured', 'PassengerInjured', 'PassengerKilled', 'PedestrianKilled',\n",
    "                    'PedestrianInjured', 'NumPedestrianVictim', 'Bus', 'Car', 'Jeepney', 'FxTaxi', 'Van', 'Truck',\n",
    "                    'Train', 'UnknownVehicle']\n",
    "ONE_HOT_COLUMNS = ['CollisionType', 'JunctionType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalization\n",
    "\n",
    "def normalize_df(df_base, columns):\n",
    "    df = df_base.copy()\n",
    "    for column in columns:\n",
    "        df[column] = normalize_max_unknown(df[column])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def normalize_max_unknown(vector):\n",
    "    min = np.min(vector)\n",
    "    max = np.max(vector)\n",
    "        \n",
    "    return [(x - float(min)) / (float(max) - float(min)) for x in vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Visualization\n",
    "\n",
    "def parallel_lines(df, target_category):\n",
    "    plt.pyplot.figure(figsize=(30,10))\n",
    "\n",
    "    parallel_plt = parallel_coordinates(df, target_category)\n",
    "#     plt.pyplot.savefig('%s_parallel.png' % target_category)\n",
    "    \n",
    "def scatter_plot(df, target_category):\n",
    "    scatter_plt = sns.pairplot(df, hue=target_category)\n",
    "    scatter_plt.savefig('%s_scatter.png' % target_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_arr(dataset, classification):\n",
    "    classification_arr = dataset[classification].values\n",
    "    del dataset[classification]\n",
    "    dataset_arr = dataset.values\n",
    "\n",
    "    return dataset_arr, classification_arr\n",
    "\n",
    "def impute_columns(df_base, columns):\n",
    "    df = df_base.copy()\n",
    "    columns = df.columns\n",
    "    for column in columns:\n",
    "        df[column] = df[column].fillna(0.0)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mmda_df = pd.read_csv(TRAIN_DATA)\n",
    "mmda_df = mmda_df.drop(NOISE_COLUMNS, axis=1)\n",
    "\n",
    "mmda_df_test = pd.read_csv(TEST_DATA)\n",
    "mmda_df_test = mmda_df_test.drop(NOISE_TEST_COLUMNS, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mmda_df_len = len(mmda_df.index)\n",
    "mmda_df_combined = mmda_df.append(mmda_df_test)\n",
    "\n",
    "mmda_df_one_hot = pd.get_dummies(mmda_df_combined, prefix=ONE_HOT_COLUMNS, columns=ONE_HOT_COLUMNS)\n",
    "\n",
    "mmda_df = mmda_df_one_hot.iloc[:mmda_df_len,:]\n",
    "mmda_df_test = mmda_df_one_hot.iloc[mmda_df_len:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imputer = Imputer(strategy='most_frequent', axis=1)\n",
    "# imputer.fit(mmda_df)\n",
    "# imputer_result = imputer.transform(mmda_df)\n",
    "\n",
    "# mmda_df_clean = pd.DataFrame(imputer_result, columns=mmda_df.columns)\n",
    "mmda_df_clean = impute_columns(mmda_df, NORMALIZE_COLUMNS)\n",
    "mmda_df_clean = normalize_df(mmda_df_clean, NORMALIZE_COLUMNS)\n",
    "\n",
    "# mmda_df_clean = mmda_df_clean.drop('AccidentCause')\n",
    "\n",
    "mmda_df_clean.to_csv(CLEAN_TRAIN_DATA)\n",
    "\n",
    "# mmda_df_clean = pd.read_csv(CLEAN_TRAIN_DATA)\n",
    "# corr_matrix = mmda_df_clean.corr()\n",
    "# corr_matrix['Classification_1'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mmda_arr, classification_arr = generate_arr(mmda_df_clean, 'Classification')\n",
    "\n",
    "classification_arr = mmda_df_clean['Classification'].values\n",
    "mmda_arr = mmda_df_clean.drop('Classification', axis=1).values\n",
    "# labels = [[x] for x in classification_arr]\n",
    "# binary_labels = MultiLabelBinarizer().fit_transform(labels)\n",
    "# binary_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mmda_predictor.pkl']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(mmda_arr, classification_arr)\n",
    "joblib.dump(clf, 'mmda_predictor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imputer_test = Imputer(strategy='most_frequent', axis=1)\n",
    "# imputer_test.fit(mmda_df_test)\n",
    "# imputer_result_test = imputer.transform(mmda_df_test)\n",
    "\n",
    "# mmda_df_clean_test = pd.DataFrame(imputer_result_test, columns=mmda_df_test.columns)\n",
    "mmda_df_clean_test = impute_columns(mmda_df_test, NORMALIZE_COLUMNS)\n",
    "mmda_df_clean_test = normalize_df(mmda_df_clean_test, NORMALIZE_COLUMNS)\n",
    "\n",
    "# mmda_df_clean_test = mmda_df_clean_test.drop('AccidentCause', axis=1)\n",
    "\n",
    "mmda_test_arr = mmda_df_clean_test.drop('Classification', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940864\n",
      "957348\n",
      "16485\n",
      "16485\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(mmda_test_arr)\n",
    "\n",
    "mmda_arr_len = len(mmda_arr)\n",
    "mmda_test_arr_len = len(mmda_test_arr)\n",
    "\n",
    "key_arr = list(range(mmda_arr_len + 1, mmda_arr_len + mmda_test_arr_len + 1))\n",
    "classification_arr = [int(x) for x in pred]\n",
    "\n",
    "print key_arr[0]\n",
    "print key_arr[-1]\n",
    "print len(key_arr)\n",
    "print len(classification_arr)\n",
    "\n",
    "index = ['Key', 'Classification']\n",
    "d = {'Key':key_arr, 'Classification': classification_arr}\n",
    "\n",
    "pred_df = pd.DataFrame(d)\n",
    "pred_df.to_csv('mmda_prediction.csv', index = False, header=True, columns=['Key', 'Classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
